{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i674a_XvH5W",
        "outputId": "12e16995-26da-431e-a2b0-a72fdef258f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mmul.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mmul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "#define N  1024\n",
        "\n",
        "__global__ void matrixMulGPU( int * a, int * b, int * c )\n",
        "{\n",
        "  int val = 0;\n",
        "\n",
        "  int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  if (row < N && col < N)\n",
        "  {\n",
        "    for ( int k = 0; k < N; ++k )\n",
        "      val += a[row * N + k] * b[k * N + col];\n",
        "    c[row * N + col] = val;\n",
        "  }\n",
        "}\n",
        "\n",
        "void matrixMulCPU( int * a, int * b, int * c )\n",
        "{\n",
        "  int val = 0;\n",
        "\n",
        "  for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      val = 0;\n",
        "      for ( int k = 0; k < N; ++k )\n",
        "        val += a[row * N + k] * b[k * N + col];\n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operations\n",
        "\n",
        "  int size = N * N * sizeof (int); // Number of bytes of an N x N matrix\n",
        "\n",
        "\n",
        "  clock_t inicio, fim; //time calculation\n",
        "  double tempo;\n",
        "\n",
        "\n",
        "  // Allocate memory\n",
        "  cudaMallocManaged (&a, size);\n",
        "  cudaMallocManaged (&b, size);\n",
        "  cudaMallocManaged (&c_cpu, size);\n",
        "  cudaMallocManaged (&c_gpu, size);\n",
        "\n",
        "  // Initialize memory; create 2D matrices\n",
        "  for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      a[row*N + col] = row;\n",
        "      b[row*N + col] = col+2;\n",
        "      c_cpu[row*N + col] = 0;\n",
        "      c_gpu[row*N + col] = 0;\n",
        "    }\n",
        "\n",
        "  \n",
        "  dim3 threads_per_block (16, 16, 1); // A 16 x 16 block threads\n",
        "  dim3 number_of_blocks ((N / threads_per_block.x) + 1, (N / threads_per_block.y) + 1, 1);\n",
        "\n",
        "  matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );\n",
        "\n",
        "  cudaDeviceSynchronize(); // Wait for the GPU to finish before proceeding\n",
        "\n",
        "  // Call the CPU version to check our work\n",
        "\n",
        "  inicio = clock();\n",
        "  matrixMulCPU( a, b, c_cpu );\n",
        "  fim = clock();\n",
        "\n",
        "  tempo = (double)(fim - inicio) / CLOCKS_PER_SEC * 1000; // Calcula o tempo de execução em segundos\n",
        "\n",
        "  // Compare the two answers to make sure they are equal\n",
        "  bool error = false;\n",
        "  for( int row = 0; row < N && !error; ++row )\n",
        "    for( int col = 0; col < N && !error; ++col )\n",
        "      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n",
        "      {\n",
        "        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n",
        "        error = true;\n",
        "        break;\n",
        "      }\n",
        "  if (!error)\n",
        "    printf(\"Success!\\n\");\n",
        "\n",
        "  // Free all our allocated memory\n",
        "  cudaFree(a); cudaFree(b);\n",
        "  cudaFree( c_cpu ); cudaFree( c_gpu );\n",
        "\n",
        "  printf(\"\\nTempo de execução: %f milissegundos para N = %d\\n\\n\\n\", tempo, N);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! mmul -nt mmul.cu ]; then nvcc mmul.cu -o mmul; fi\n",
        "! nvprof ./mmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "966lE7ub39hN",
        "outputId": "aaa1e08b-6126-4e50-a1f5-4c7d64be4c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1340== NVPROF is profiling process 1340, command: ./mmul\n",
            "Success!\n",
            "\n",
            "Tempo de execução: 6018.100000 milissegundos para N = 1024\n",
            "\n",
            "\n",
            "==1340== Profiling application: ./mmul\n",
            "==1340== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  53.047ms         1  53.047ms  53.047ms  53.047ms  matrixMulGPU(int*, int*, int*)\n",
            "      API calls:   81.91%  247.18ms         4  61.795ms  13.346us  247.08ms  cudaMallocManaged\n",
            "                   17.58%  53.058ms         1  53.058ms  53.058ms  53.058ms  cudaDeviceSynchronize\n",
            "                    0.43%  1.3118ms         4  327.94us  180.79us  464.71us  cudaFree\n",
            "                    0.05%  140.89us       101  1.3940us     135ns  54.563us  cuDeviceGetAttribute\n",
            "                    0.02%  56.519us         1  56.519us  56.519us  56.519us  cudaLaunchKernel\n",
            "                    0.01%  27.172us         1  27.172us  27.172us  27.172us  cuDeviceGetName\n",
            "                    0.00%  6.2850us         1  6.2850us  6.2850us  6.2850us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2360us         3     745ns     254ns  1.6120us  cuDeviceGetCount\n",
            "                    0.00%  1.0660us         2     533ns     313ns     753ns  cuDeviceGet\n",
            "                    0.00%     743ns         1     743ns     743ns     743ns  cuModuleGetLoadingMode\n",
            "                    0.00%     520ns         1     520ns     520ns     520ns  cuDeviceTotalMem\n",
            "                    0.00%     212ns         1     212ns     212ns     212ns  cuDeviceGetUuid\n",
            "\n",
            "==1340== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     338  36.355KB  4.0000KB  0.9883MB  12.00000MB  1.914505ms  Host To Device\n",
            "      72  170.67KB  4.0000KB  0.9961MB  12.00000MB  1.100067ms  Device To Host\n",
            "      20         -         -         -           -  4.981496ms  Gpu page fault groups\n",
            "Total CPU Page faults: 84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6Dv7Jix4CmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}